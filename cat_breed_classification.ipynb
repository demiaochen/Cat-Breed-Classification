{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "    \n",
    "# Test network on validation set, if it exists.\n",
    "def test_network(net,testloader,print_confusion=False):\n",
    "    net.eval()\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "    conf_matrix = np.zeros((8,8))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            conf_matrix = conf_matrix + metrics.confusion_matrix(\n",
    "                labels.cpu(),predicted.cpu(),labels=[0,1,2,3,4,5,6,7])\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    print(', {0} test {1:.2f}%'.format(total_images,model_accuracy))\n",
    "    if print_confusion:\n",
    "        np.set_printoptions(precision=2, suppress=True)\n",
    "        print(conf_matrix)\n",
    "    net.train()\n",
    "\n",
    "def main():\n",
    "    print(\"Using device: {}\"\n",
    "          \"\\n\".format(str(device)))\n",
    "    ########################################################################\n",
    "    #######                      Loading Data                        #######\n",
    "    ########################################################################\n",
    "    data = torchvision.datasets.ImageFolder(root=student.dataset)\n",
    "    \n",
    "    if student.train_val_split == 1:\n",
    "        # Train on the entire dataset\n",
    "        data = torchvision.datasets.ImageFolder(root=student.dataset,\n",
    "                            transform=student.transform('train'))\n",
    "        trainloader = torch.utils.data.DataLoader(data,\n",
    "                            batch_size=student.batch_size, shuffle=True);\n",
    "    else:\n",
    "        # Split the dataset into trainset and testset\n",
    "        data = torchvision.datasets.ImageFolder(root=student.dataset)\n",
    "        data.len=len(data)\n",
    "        train_len = int((student.train_val_split)*data.len)\n",
    "        test_len = data.len - train_len\n",
    "        train_subset, test_subset = random_split(data, [train_len, test_len])\n",
    "        trainset = DatasetFromSubset(\n",
    "            train_subset, transform=student.transform('train'))\n",
    "        testset = DatasetFromSubset(\n",
    "            test_subset, transform=student.transform('test'))\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                            batch_size=student.batch_size, shuffle=False)\n",
    "        testloader = torch.utils.data.DataLoader(testset, \n",
    "                            batch_size=student.batch_size, shuffle=False)\n",
    "\n",
    "    # Get model, loss criterion and optimizer from student\n",
    "    net = student.net.to(device)\n",
    "    criterion = student.loss_func\n",
    "    optimizer = student.optimizer\n",
    "    # get weight initialization and lr scheduler, if appropriate\n",
    "    weights_init = student.weights_init\n",
    "    scheduler = student.scheduler\n",
    "\n",
    "    # apply custom weight initialization, if it exists\n",
    "    net.apply(weights_init)\n",
    "    \n",
    "    ########################################################################\n",
    "    #######                        Training                          #######\n",
    "    ########################################################################\n",
    "    print(\"Start training...\")\n",
    "    for epoch in range(1,student.epochs+1):\n",
    "        total_loss = 0\n",
    "        total_images = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in trainloader:           # Load batch\n",
    "            images, labels = batch \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = net(images)             # Process batch\n",
    "            \n",
    "            loss = criterion(preds, labels) # Calculate loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()                 # Calculate gradients\n",
    "            optimizer.step()                # Update weights\n",
    "\n",
    "            output = preds.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += output.eq(labels).sum().item()\n",
    "\n",
    "        # apply lr schedule, if it exists\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        model_accuracy = total_correct / total_images * 100\n",
    "        print('ep {0}, loss: {1:.2f}, {2} train {3:.2f}%'.format(\n",
    "               epoch, total_loss, total_images, model_accuracy), end='')\n",
    "\n",
    "        if student.train_val_split < 1:\n",
    "            test_network(net,testloader,\n",
    "                         print_confusion=(epoch % 10 == 0))\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(net.state_dict(),'checkModel.pth')\n",
    "            print(\"   Model saved to checkModel.pth\")        \n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    torch.save(net.state_dict(),'savedModel.pth')\n",
    "    print(\"   Model saved to savedModel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**student.py**\n",
    "\n",
    "UNSW COMP9444 Neural Networks and Deep Learning\n",
    "\n",
    "You may modify this file however you wish, including creating additional\n",
    "variables, functions, classes, etc., so long as your code runs with the\n",
    "hw2main.py file unmodified, and you are only using the approved packages.\n",
    "\n",
    "You have been given some default values for the variables train_val_split,\n",
    "batch_size as well as the transform function.\n",
    "You are encouraged to modify these to improve the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question:**\n",
    "\n",
    "Briefly describe how your program works, and explain any design and training\n",
    "decisions you made along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "######     Specify transform(s) to be applied to the input images     ######\n",
    "############################################################################\n",
    "def transform(mode):\n",
    "    \"\"\"\n",
    "    Called when loading the data. Visit this URL for more information:\n",
    "    https://pytorch.org/vision/stable/transforms.html\n",
    "    You may specify different transforms for training and testing\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        return transforms.ToTensor()\n",
    "    elif mode == 'test':\n",
    "        return transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "net = Network()\n",
    "    \n",
    "############################################################################\n",
    "######      Specify the optimizer and loss function                   ######\n",
    "############################################################################\n",
    "optimizer = None\n",
    "\n",
    "loss_func = None\n",
    "\n",
    "\n",
    "############################################################################\n",
    "######  Custom weight initialization and lr scheduling are optional   ######\n",
    "############################################################################\n",
    "\n",
    "# Normally, the default weight initialization and fixed learing rate\n",
    "# should work fine. But, we have made it possible for you to define\n",
    "# your own custom weight initialization and lr scheduler, if you wish.\n",
    "def weights_init(m):\n",
    "    return\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "############################################################################\n",
    "#######              Metaparameters and training options              ######\n",
    "############################################################################\n",
    "dataset = \"./data\"\n",
    "train_val_split = 0.8\n",
    "batch_size = 200\n",
    "epochs = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
