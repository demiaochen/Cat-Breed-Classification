{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from helper import get_cat_count, count_parameters, compute_confusion_matrix, show_examples, plot_training_loss, plot_accuracy, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9444 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat breed classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**student.py**\n",
    "\n",
    "UNSW COMP9444 Neural Networks and Deep Learning\n",
    "\n",
    "You may modify this file however you wish, including creating additional\n",
    "variables, functions, classes, etc., so long as your code runs with the\n",
    "hw2main.py file unmodified, and you are only using the approved packages.\n",
    "\n",
    "You have been given some default values for the variables train_val_split,\n",
    "batch_size as well as the transform function.\n",
    "You are encouraged to modify these to improve the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question:**\n",
    "\n",
    "Briefly describe how your program works, and explain any design and training\n",
    "decisions you made along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "######     Specify transform(s) to be applied to the input images     ######\n",
    "############################################################################\n",
    "\n",
    "def transform(mode):\n",
    "    \"\"\"\n",
    "    Called when loading the data. Visit this URL for more information:\n",
    "    https://pytorch.org/vision/stable/transforms.html\n",
    "    You may specify different transforms for training and testing\n",
    "    \"\"\"\n",
    "\n",
    "    # channel size = 3\n",
    "\n",
    "def transform(mode):\n",
    "    \"\"\"\n",
    "    Called when loading the data. Visit this URL for more information:\n",
    "    https://pytorch.org/vision/stable/transforms.html\n",
    "    You may specify different transforms for training and testing\n",
    "    \"\"\"\n",
    "    # Data Augmentation\n",
    "    if mode == 'train':\n",
    "        return transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomResizedCrop(size=80, scale=(0.45, 1.0), ratio=(0.70, 1.4)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomPerspective(p=0.2),\n",
    "                transforms.RandomAffine(degrees=(-15, 15), translate=(0.0, 0.5)),\n",
    "                transforms.RandomRotation((-10,10)),\n",
    "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.1, hue=0.02),\n",
    "                transforms.RandomPosterize(bits=3, p=0.3),\n",
    "                transforms.RandomEqualize(p=0.1),\n",
    "                transforms.RandomGrayscale(p=0.01),\n",
    "                transforms.RandomPerspective(distortion_scale=0.05, p=0.15, fill=0),\n",
    "                transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "                transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "    # Keep the testing data original to ensure accuracy\n",
    "    elif mode == 'test':\n",
    "        return transforms.Compose(\n",
    "            [   \n",
    "                transforms.ToTensor()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#####                      Specify NN to be used                           ######\n",
    "#################################################################################\n",
    "\n",
    "### Simplified implementation of VGG16 with 12 layers instead of 16.\n",
    "### Cut layer = 256 - 256 conv layer. 512-512 * 3 conv layers at the end.\n",
    "### Reduced number of nodes on FC layer from 4096 to 1024.\n",
    "vgg_12 = [64, 64, 'maxpool', 128, 128, 'maxpool', 256, 256, 'maxpool', 512, 512, 512, 'maxpool', 'avgpool', 'fc1', 'fc2', 'fc3']    \n",
    "##########################################################################################\n",
    "# trying to take some inspirations from vgg16 but with less channels and fc layer nodes. #\n",
    "##########################################################################################\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            ######### block 1 #########\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            \n",
    "            ######### block 2 #########\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            ######### block 3 #########   \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "        \n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            \n",
    "            ######### block 4 #########\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 192, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        # shrink final conv layer width to 4\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten from conv layers\n",
    "\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(192*4*4, 3600),\n",
    "            nn.BatchNorm1d(3600),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(3600, 1800),\n",
    "            nn.BatchNorm1d(1800),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1800, 8)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.avgpool(x)       \n",
    "        x = self.fc_layers(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Network()\n",
    "\n",
    "############################################################################\n",
    "######      Specify the optimizer and loss function                   ######\n",
    "############################################################################\n",
    "learning_rate = 0.0005\n",
    "# optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=learning_rate)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# loss_func = F.nll_loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "############################################################################\n",
    "######  Custom weight initialization and lr scheduling are optional   ######\n",
    "############################################################################\n",
    "\n",
    "# Normally, the default weight initialization and fixed learing rate\n",
    "# should work fine. But, we have made it possible for you to define\n",
    "# your own custom weight initialization and lr scheduler, if you wish.\n",
    "def weights_init(m):\n",
    "    return\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#######              Metaparameters and training options              ######\n",
    "############################################################################\n",
    "dataset = \"./data\"\n",
    "train_val_split = 1\n",
    "batch_size = 256 \n",
    "epochs = 1200\n",
    "\n",
    "\n",
    "###############################################\n",
    "#**          Print Network Information      **#\n",
    "###############################################\n",
    "print(transform('train'))\n",
    "print(net)\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 2 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###########################\n",
    "## Cat breed dictionary  ##\n",
    "###########################\n",
    "cat_dict = {\n",
    "    0: 'bombay',\n",
    "    1: 'calico',\n",
    "    2: 'persian',\n",
    "    3: 'russianblue',\n",
    "    4: 'siamese',\n",
    "    5: 'tiger',\n",
    "    6: 'tortoiseshell',\n",
    "    7: 'tuxedo'\n",
    "}\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "# Test network on validation set, if it exists.\n",
    "## Added params\n",
    "def test_network(net,testloader,test_accuracy_list,print_confusion=False):\n",
    "    net.eval()\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "    conf_matrix = np.zeros((8,8))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            conf_matrix = conf_matrix + metrics.confusion_matrix(\n",
    "                labels.cpu(),predicted.cpu(),labels=[0,1,2,3,4,5,6,7])\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    test_accuracy_list.append(model_accuracy)\n",
    "    print(', {0} test {1:.2f}%'.format(total_images,model_accuracy))\n",
    "    if print_confusion:\n",
    "        np.set_printoptions(precision=2, suppress=True)\n",
    "        print(conf_matrix)\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "### Tracking training time ###\n",
    "##############################\n",
    "start_time = time.time() ## Added\n",
    "time_elapsed = 0  ## Added Line\n",
    "##############################\n",
    "\n",
    "###############################\n",
    "### Tracking nn performance ###\n",
    "###############################\n",
    "minibatch_loss_list, train_accuracy_list, test_accuracy_list = [], [], [] ## Added\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "# Main\n",
    "print(\"Using device: {}\"\n",
    "      \"\\n\".format(str(device)))\n",
    "########################################################################\n",
    "#######                      Loading Data                        #######\n",
    "########################################################################\n",
    "data = torchvision.datasets.ImageFolder(root=dataset)\n",
    "\n",
    "if train_val_split == 1:\n",
    "    # Train on the entire dataset\n",
    "    data = torchvision.datasets.ImageFolder(root=dataset,\n",
    "                        transform=transform('train'))\n",
    "    trainloader = torch.utils.data.DataLoader(data,\n",
    "                        batch_size=batch_size, shuffle=True);\n",
    "else:\n",
    "    # Split the dataset into trainset and testset\n",
    "    data = torchvision.datasets.ImageFolder(root=dataset)\n",
    "    data.len=len(data)\n",
    "    train_len = int((train_val_split)*data.len)\n",
    "    test_len = data.len - train_len\n",
    "    train_subset, test_subset = random_split(data, [train_len, test_len])\n",
    "    trainset = DatasetFromSubset(\n",
    "        train_subset, transform=transform('train'))\n",
    "    testset = DatasetFromSubset(\n",
    "        test_subset, transform=transform('test'))\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "    testloader = torch.utils.data.DataLoader(testset, \n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Get model, loss criterion and optimizer from student\n",
    "net = net.to(device)\n",
    "criterion = loss_func\n",
    "optimizer = optimizer\n",
    "# get weight initialization and lr scheduler, if appropriate\n",
    "weights_init = weights_init\n",
    "scheduler = scheduler\n",
    "\n",
    "# apply custom weight initialization, if it exists\n",
    "net.apply(weights_init)\n",
    "\n",
    "########################################################################\n",
    "#######                        Training                          #######\n",
    "########################################################################\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1,epochs+1):\n",
    "    total_loss = 0\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in trainloader:           # Load batch\n",
    "        images, labels = batch \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = net(images)             # Process batch\n",
    "\n",
    "        loss = criterion(preds, labels) # Calculate loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()                 # Calculate gradients\n",
    "        optimizer.step()                # Update weights\n",
    "\n",
    "        output = preds.argmax(dim=1)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_images += labels.size(0)\n",
    "        total_correct += output.eq(labels).sum().item()\n",
    "        minibatch_loss_list.append(loss.item())  ## Added\n",
    "\n",
    "    # apply lr schedule, if it exists\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100 \n",
    "    train_accuracy_list.append(model_accuracy)  ## Added\n",
    "    print('ep {0}, loss: {1:.2f}, {2} train {3:.2f}%'.format(\n",
    "           epoch, total_loss, total_images, model_accuracy), end='')\n",
    "\n",
    "    if train_val_split < 1:\n",
    "        test_network(net,testloader, test_accuracy_list,\n",
    "                     print_confusion=(epoch % 10 == 0)) ## Added\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "   \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(net.state_dict(),'v4_check.pth')\n",
    "        print(\"   Model saved to checkModel.pth\")\n",
    "        time_elapsed = time.time() - start_time  ## Added Line\n",
    "        print(f'Time elapsed: {str(datetime.timedelta(seconds = time_elapsed))}') ## TIME\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(net.state_dict(), f'{epoch}_saved.pth')\n",
    "        print(f\"   Model saved to {epoch}_saved.pth\")\n",
    "    \n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(),'v4_final_saved.pth')\n",
    "print(\"   Model saved to savedModel.pth\")\n",
    "time_elapsed = time.time() - start_time ## Added Line\n",
    "print(f'total time needed to train network: \\\n",
    "        {str(datetime.timedelta(seconds = time_elapsed))}\\ntotal time in seconds: {time_elapsed}') ## TIME\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#**        Data Information     **#\n",
    "###################################\n",
    "print(f'batch size: {batch_size}')\n",
    "print(f'learning rate: {learning_rate}')\n",
    "print(f'train_val_split: {train_val_split}')\n",
    "print(f'epochs: {epochs}')\n",
    "\n",
    "\n",
    "#############################\n",
    "#**         END           **#\n",
    "#############################\n",
    "\n",
    "\n",
    "# Getting count of each cat breed, should be close to 8*0.8*1000 initially..\n",
    "train_data_distribution = get_cat_count(trainloader, 'training data')\n",
    "# Getting count of each cat breed, should be close to 8*0.2*1000 initially..\n",
    "test_data_distribution = get_cat_count(testloader, 'test data')\n",
    "\n",
    "print(f'training data distribution - {train_data_distribution}')\n",
    "print(f'test data distribution - {test_data_distribution}')\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=epochs,\n",
    "                   iter_per_epoch=len(trainloader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy(train_acc_list=train_accuracy_list,\n",
    "              test_acc_list=test_accuracy_list,\n",
    "              results_dir=None)\n",
    "plt.show()\n",
    "\n",
    "net.cpu()\n",
    "show_examples(model=net, data_loader=testloader, class_dict=cat_dict)\n",
    "\n",
    "conf_matrix = compute_confusion_matrix(model=net, data_loader=testloader, device=torch.device('cpu'))\n",
    "print(conf_matrix)\n",
    "plot_confusion_matrix(conf_matrix, class_names=cat_dict.values(), test_data_distribution=test_data_distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
