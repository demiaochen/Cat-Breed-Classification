{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from helper import get_cat_count, count_parameters, compute_confusion_matrix, show_examples, plot_training_loss, plot_accuracy, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9444 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat breed classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**student.py**\n",
    "\n",
    "UNSW COMP9444 Neural Networks and Deep Learning\n",
    "\n",
    "You may modify this file however you wish, including creating additional\n",
    "variables, functions, classes, etc., so long as your code runs with the\n",
    "hw2main.py file unmodified, and you are only using the approved packages.\n",
    "\n",
    "You have been given some default values for the variables train_val_split,\n",
    "batch_size as well as the transform function.\n",
    "You are encouraged to modify these to improve the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question:**\n",
    "\n",
    "Briefly describe how your program works, and explain any design and training\n",
    "decisions you made along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "######     Specify transform(s) to be applied to the input images     ######\n",
    "############################################################################\n",
    "\n",
    "def transform(mode):\n",
    "    \"\"\"\n",
    "    Called when loading the data. Visit this URL for more information:\n",
    "    https://pytorch.org/vision/stable/transforms.html\n",
    "    You may specify different transforms for training and testing\n",
    "    \"\"\"\n",
    "\n",
    "    # channel size = 3\n",
    "\n",
    "    if mode == 'train':\n",
    "        return transforms.Compose(\n",
    "            [   \n",
    "                # transforms.RandomCrop((64, 64)),\n",
    "                transforms.RandomResizedCrop(size=80, \n",
    "                         scale=(0.75, 1.0), ratio=(0.75, 1.3)), # original 80*80, avoid cropping important info\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation((-10,10)),\n",
    "                transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "                transforms.RandomPosterize(bits=3, p=0.4),\n",
    "                transforms.RandomEqualize(p=0.1),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.RandomPerspective(distortion_scale=0.05, p=0.1, fill=0),\n",
    "                ## T.RandomErasing(),\n",
    "                ## T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "                ## T.RandomInvert(p=0.05),\n",
    "                transforms.ToTensor()\n",
    "                ## Standardize each channel of the image\n",
    "                ## T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    elif mode == 'test':\n",
    "        return transforms.Compose(\n",
    "            [   \n",
    "                # transforms.CenterCrop((64, 64)),\n",
    "                transforms.ToTensor()\n",
    "                ## Standardize each channel of the image\n",
    "                ## transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                ##                                 [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(80, 80), scale=(0.75, 1.0), ratio=(0.75, 1.3), interpolation=bilinear)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=[0.6, 1.4], contrast=[0.7, 1.3], saturation=[0.7, 1.3], hue=[-0.2, 0.2])\n",
      "    RandomPosterize(bits=3,p=0.4)\n",
      "    RandomEqualize(p=0.1)\n",
      "    RandomGrayscale(p=0.1)\n",
      "    RandomPerspective(p=0.1)\n",
      "    ToTensor()\n",
      ")\n",
      "VGG12(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0, inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ELU(alpha=1.0, inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ELU(alpha=1.0, inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ELU(alpha=1.0, inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ELU(alpha=1.0, inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ELU(alpha=1.0, inplace=True)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ELU(alpha=1.0, inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ELU(alpha=1.0, inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=4608, out_features=1024, bias=True)\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.6, inplace=False)\n",
      "    (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.4, inplace=False)\n",
      "    (9): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "+----------------------+------------+\n",
      "|       Modules        | Parameters |\n",
      "+----------------------+------------+\n",
      "| cnn_layers.0.weight  |    1728    |\n",
      "|  cnn_layers.0.bias   |     64     |\n",
      "| cnn_layers.1.weight  |     64     |\n",
      "|  cnn_layers.1.bias   |     64     |\n",
      "| cnn_layers.3.weight  |   36864    |\n",
      "|  cnn_layers.3.bias   |     64     |\n",
      "| cnn_layers.4.weight  |     64     |\n",
      "|  cnn_layers.4.bias   |     64     |\n",
      "| cnn_layers.7.weight  |   73728    |\n",
      "|  cnn_layers.7.bias   |    128     |\n",
      "| cnn_layers.8.weight  |    128     |\n",
      "|  cnn_layers.8.bias   |    128     |\n",
      "| cnn_layers.10.weight |   147456   |\n",
      "|  cnn_layers.10.bias  |    128     |\n",
      "| cnn_layers.11.weight |    128     |\n",
      "|  cnn_layers.11.bias  |    128     |\n",
      "| cnn_layers.14.weight |   294912   |\n",
      "|  cnn_layers.14.bias  |    256     |\n",
      "| cnn_layers.15.weight |    256     |\n",
      "|  cnn_layers.15.bias  |    256     |\n",
      "| cnn_layers.17.weight |   589824   |\n",
      "|  cnn_layers.17.bias  |    256     |\n",
      "| cnn_layers.18.weight |    256     |\n",
      "|  cnn_layers.18.bias  |    256     |\n",
      "| cnn_layers.21.weight |  1179648   |\n",
      "|  cnn_layers.21.bias  |    512     |\n",
      "| cnn_layers.22.weight |    512     |\n",
      "|  cnn_layers.22.bias  |    512     |\n",
      "| cnn_layers.24.weight |  2359296   |\n",
      "|  cnn_layers.24.bias  |    512     |\n",
      "| cnn_layers.25.weight |    512     |\n",
      "|  cnn_layers.25.bias  |    512     |\n",
      "| cnn_layers.27.weight |  2359296   |\n",
      "|  cnn_layers.27.bias  |    512     |\n",
      "| cnn_layers.28.weight |    512     |\n",
      "|  cnn_layers.28.bias  |    512     |\n",
      "|  fc_layers.1.weight  |  4718592   |\n",
      "|   fc_layers.1.bias   |    1024    |\n",
      "|  fc_layers.2.weight  |    1024    |\n",
      "|   fc_layers.2.bias   |    1024    |\n",
      "|  fc_layers.5.weight  |  1048576   |\n",
      "|   fc_layers.5.bias   |    1024    |\n",
      "|  fc_layers.6.weight  |    1024    |\n",
      "|   fc_layers.6.bias   |    1024    |\n",
      "|  fc_layers.9.weight  |    8192    |\n",
      "|   fc_layers.9.bias   |     8      |\n",
      "+----------------------+------------+\n",
      "Total Trainable Params: 12831560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12831560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################\n",
    "#####                      Specify NN to be used                           ######\n",
    "#################################################################################\n",
    "\n",
    "### Simplified implementation of VGG16 with 12 layers instead of 16.\n",
    "### Cut layer = 256 - 256 conv layer. 512-512 * 3 conv layers at the end.\n",
    "### Reduced number of nodes on FC layer from 4096 to 1024.\n",
    "vgg_12 = [64, 64, 'maxpool', 128, 128, 'maxpool', 256, 256, 'maxpool', 512, 512, 512, 'maxpool', 'avgpool', 'fc1', 'fc2', 'fc3']    \n",
    "##########################################################################################\n",
    "# trying to take some inspirations from vgg16 but with less channels and fc layer nodes. #\n",
    "##########################################################################################\n",
    "class VGG12(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            ######### block 1 #########\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            \n",
    "            ######### block 2 #########\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            ######### block 3 #########   \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "        \n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            \n",
    "            \n",
    "            ######### block 4 #########\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        # shrink final conv layer width to 4\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512*3*3, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1024, 8)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc_layers(x)\n",
    "        return F.log_softmax(x, dim=1)       \n",
    "    \n",
    "\n",
    "####################################################################################################################\n",
    "# Re-implementation of AlexNet                                                                                     #\n",
    "# https://github.com/pytorch/vision/blob/693829121bdc3e26714691f70241c6c01a089457/torchvision/models/alexnet.py    #\n",
    "# Added Batch normalization, Leaky ReLU to prevent overfitting, reduced neurons in Hidden FC Layers for size res.  #\n",
    "####################################################################################################################\n",
    "class AlexNetModified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d((3, 3), stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d((3, 3), stride=2),\n",
    "            \n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2)\n",
    "        )\n",
    "        \n",
    "        # shrink final conv layer width to 6\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(256*6*6, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1000, 8)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "net = VGG12()\n",
    "\n",
    "############################################################################\n",
    "######      Specify the optimizer and loss function                   ######\n",
    "############################################################################\n",
    "learning_rate = 0.0005\n",
    "# optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=learning_rate)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# loss_func = F.nll_loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "############################################################################\n",
    "######  Custom weight initialization and lr scheduling are optional   ######\n",
    "############################################################################\n",
    "\n",
    "# Normally, the default weight initialization and fixed learing rate\n",
    "# should work fine. But, we have made it possible for you to define\n",
    "# your own custom weight initialization and lr scheduler, if you wish.\n",
    "def weights_init(m):\n",
    "    return\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#######              Metaparameters and training options              ######\n",
    "############################################################################\n",
    "dataset = \"./data\"\n",
    "train_val_split = 0.8\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "###############################################\n",
    "#**          Print Network Information      **#\n",
    "###############################################\n",
    "print(transform('train'))\n",
    "print(net)\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 2 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###########################\n",
    "## Cat breed dictionary  ##\n",
    "###########################\n",
    "cat_dict = {\n",
    "    0: 'bombay',\n",
    "    1: 'calico',\n",
    "    2: 'persian',\n",
    "    3: 'russianblue',\n",
    "    4: 'siamese',\n",
    "    5: 'tiger',\n",
    "    6: 'tortoiseshell',\n",
    "    7: 'tuxedo'\n",
    "}\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "# Test network on validation set, if it exists.\n",
    "## Added params\n",
    "def test_network(net,testloader,test_accuracy_list,print_confusion=False):\n",
    "    net.eval()\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "    conf_matrix = np.zeros((8,8))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            conf_matrix = conf_matrix + metrics.confusion_matrix(\n",
    "                labels.cpu(),predicted.cpu(),labels=[0,1,2,3,4,5,6,7])\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    test_accuracy_list.append(model_accuracy)\n",
    "    print(', {0} test {1:.2f}%'.format(total_images,model_accuracy))\n",
    "    if print_confusion:\n",
    "        np.set_printoptions(precision=2, suppress=True)\n",
    "        print(conf_matrix)\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "Start training...\n",
      "ep 1, loss: 59.93, 6400 train 26.80%, 1600 test 34.75%\n",
      "Time elapsed: 0:00:27.066313\n",
      "ep 2, loss: 54.72, 6400 train 34.08%, 1600 test 33.44%\n",
      "Time elapsed: 0:00:44.261528\n",
      "ep 3, loss: 52.16, 6400 train 38.56%, 1600 test 42.38%\n",
      "Time elapsed: 0:01:01.465020\n",
      "ep 4, loss: 49.42, 6400 train 41.77%, 1600 test 42.50%\n",
      "Time elapsed: 0:01:18.711215\n",
      "ep 5, loss: 48.50, 6400 train 42.91%, 1600 test 42.75%\n",
      "Time elapsed: 0:01:36.041571\n",
      "ep 6, loss: 46.29, 6400 train 45.25%, 1600 test 47.75%\n",
      "Time elapsed: 0:01:53.945118\n",
      "ep 7, loss: 44.75, 6400 train 48.09%, 1600 test 49.88%\n",
      "Time elapsed: 0:02:11.999722\n",
      "ep 8, loss: 43.36, 6400 train 48.67%, 1600 test 45.25%\n",
      "Time elapsed: 0:02:30.200895\n",
      "ep 9, loss: 42.17, 6400 train 50.62%, 1600 test 52.50%\n",
      "Time elapsed: 0:02:48.108680\n",
      "ep 10, loss: 41.08, 6400 train 52.73%, 1600 test 51.88%\n",
      "[[129.   2.   0.   7.   0.   8.  17.  34.]\n",
      " [  0.  75.   6.   5.  10.  67.  26.  22.]\n",
      " [ 10.   8.  75.  16.  15.  59.   7.   8.]\n",
      " [ 28.   1.   1.  63.   1.  74.  15.   6.]\n",
      " [  4.  30.  38.  24.  58.  34.  11.  19.]\n",
      " [  2.   2.   1.   2.   0. 200.   4.   2.]\n",
      " [ 10.   5.   0.   0.   0.  55.  94.  16.]\n",
      " [ 20.  16.   1.   2.   2.   6.  11. 136.]]\n",
      "Time elapsed: 0:03:05.581015\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:03:05.648015\n",
      "total time in seconds: 185.64801502227783\n",
      "ep 11, loss: 39.47, 6400 train 54.62%, 1600 test 51.81%\n",
      "Time elapsed: 0:03:23.514737\n",
      "ep 12, loss: 38.45, 6400 train 56.20%, 1600 test 51.12%\n",
      "Time elapsed: 0:03:41.672289\n",
      "ep 13, loss: 37.45, 6400 train 57.06%, 1600 test 52.12%\n",
      "Time elapsed: 0:03:59.589147\n",
      "ep 14, loss: 36.81, 6400 train 58.08%, 1600 test 49.69%\n",
      "Time elapsed: 0:04:17.670210\n",
      "ep 15, loss: 36.26, 6400 train 59.36%, 1600 test 62.00%\n",
      "Time elapsed: 0:04:35.188090\n",
      "ep 16, loss: 35.20, 6400 train 60.77%, 1600 test 52.75%\n",
      "Time elapsed: 0:04:53.105064\n",
      "ep 17, loss: 34.08, 6400 train 62.31%, 1600 test 51.88%\n",
      "Time elapsed: 0:05:11.154371\n",
      "ep 18, loss: 33.15, 6400 train 63.27%, 1600 test 51.88%\n",
      "Time elapsed: 0:05:28.851573\n",
      "ep 19, loss: 33.01, 6400 train 63.45%, 1600 test 59.94%\n",
      "Time elapsed: 0:05:46.616749\n",
      "ep 20, loss: 31.85, 6400 train 64.58%, 1600 test 65.00%\n",
      "[[148.   0.   2.  22.   1.   3.   2.  19.]\n",
      " [  3.  88.  10.   9.  11.  53.   8.  29.]\n",
      " [  8.   5. 120.  15.  23.  20.   1.   6.]\n",
      " [ 11.   2.   8. 148.   1.  17.   0.   2.]\n",
      " [  3.  10.  23.  37. 118.  12.   2.  13.]\n",
      " [  0.   3.   2.  12.   1. 195.   0.   0.]\n",
      " [ 15.   9.  18.  12.   0.  44.  72.  10.]\n",
      " [ 21.   7.   6.   6.   1.   1.   1. 151.]]\n",
      "Time elapsed: 0:06:04.834144\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:06:04.904146\n",
      "total time in seconds: 364.90414571762085\n",
      "ep 21, loss: 31.27, 6400 train 65.12%, 1600 test 55.25%\n",
      "Time elapsed: 0:06:22.518284\n",
      "ep 22, loss: 30.77, 6400 train 65.69%, 1600 test 58.50%\n",
      "Time elapsed: 0:06:39.871467\n",
      "ep 23, loss: 30.89, 6400 train 65.78%, 1600 test 56.75%\n",
      "Time elapsed: 0:06:57.265667\n",
      "ep 24, loss: 29.86, 6400 train 66.41%, 1600 test 60.75%\n",
      "Time elapsed: 0:07:14.610154\n",
      "ep 25, loss: 29.55, 6400 train 67.05%, 1600 test 59.56%\n",
      "Time elapsed: 0:07:32.245011\n",
      "ep 26, loss: 29.22, 6400 train 68.38%, 1600 test 65.81%\n",
      "Time elapsed: 0:07:50.341262\n",
      "ep 27, loss: 27.53, 6400 train 68.89%, 1600 test 62.00%\n",
      "Time elapsed: 0:08:08.045079\n",
      "ep 28, loss: 27.21, 6400 train 69.89%, 1600 test 60.25%\n",
      "Time elapsed: 0:08:25.492140\n",
      "ep 29, loss: 26.56, 6400 train 70.48%, 1600 test 62.56%\n",
      "Time elapsed: 0:08:42.962090\n",
      "ep 30, loss: 26.20, 6400 train 71.25%, 1600 test 64.44%\n",
      "[[177.   0.   0.  14.   1.   2.   0.   3.]\n",
      " [  6.  65.   1.  15.  42.  48.   3.  31.]\n",
      " [ 13.   4. 101.  15.  35.  24.   0.   6.]\n",
      " [ 22.   0.   1. 147.   9.   9.   0.   1.]\n",
      " [  4.   2.   4.  20. 173.   6.   1.   8.]\n",
      " [  2.   4.   1.  11.   0. 194.   0.   1.]\n",
      " [ 51.   7.   3.  27.   1.  46.  36.   9.]\n",
      " [ 37.   3.   2.   8.   4.   1.   1. 138.]]\n",
      "Time elapsed: 0:09:00.358729\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:09:00.432737\n",
      "total time in seconds: 540.4327371120453\n",
      "ep 31, loss: 25.11, 6400 train 72.39%, 1600 test 66.94%\n",
      "Time elapsed: 0:09:17.821529\n",
      "ep 32, loss: 25.40, 6400 train 72.00%, 1600 test 64.25%\n",
      "Time elapsed: 0:09:35.367274\n",
      "ep 33, loss: 24.72, 6400 train 72.61%, 1600 test 63.62%\n",
      "Time elapsed: 0:09:52.837248\n",
      "ep 34, loss: 24.43, 6400 train 73.05%, 1600 test 69.75%\n",
      "Time elapsed: 0:10:10.344422\n",
      "ep 35, loss: 24.64, 6400 train 73.12%, 1600 test 61.06%\n",
      "Time elapsed: 0:10:27.831476\n",
      "ep 36, loss: 24.19, 6400 train 73.30%, 1600 test 71.31%\n",
      "Time elapsed: 0:10:45.497686\n",
      "ep 37, loss: 24.16, 6400 train 73.73%, 1600 test 65.25%\n",
      "Time elapsed: 0:11:03.166556\n",
      "ep 38, loss: 23.48, 6400 train 74.25%, 1600 test 62.62%\n",
      "Time elapsed: 0:11:20.845580\n",
      "ep 39, loss: 22.35, 6400 train 75.59%, 1600 test 65.88%\n",
      "Time elapsed: 0:11:38.205184\n",
      "ep 40, loss: 21.82, 6400 train 76.03%, 1600 test 69.38%\n",
      "[[162.   0.   1.   3.   1.   2.  14.  14.]\n",
      " [  1.  64.   3.   9.  43.  26.  33.  32.]\n",
      " [  8.   3. 108.   7.  47.  10.   8.   7.]\n",
      " [ 38.   0.   5. 130.   3.   5.   6.   2.]\n",
      " [  7.   1.   2.  14. 175.   5.   7.   7.]\n",
      " [  1.   1.   1.  12.   2. 185.   7.   4.]\n",
      " [ 18.   2.   4.   3.   1.   8. 138.   6.]\n",
      " [ 27.   3.   2.   3.   2.   0.   9. 148.]]\n",
      "Time elapsed: 0:11:55.690345\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:11:55.763556\n",
      "total time in seconds: 715.7635562419891\n",
      "ep 41, loss: 22.62, 6400 train 74.86%, 1600 test 73.12%\n",
      "Time elapsed: 0:12:13.350610\n",
      "ep 42, loss: 21.98, 6400 train 76.39%, 1600 test 65.38%\n",
      "Time elapsed: 0:12:30.931853\n",
      "ep 43, loss: 21.53, 6400 train 76.36%, 1600 test 67.31%\n",
      "Time elapsed: 0:12:48.438356\n",
      "ep 44, loss: 20.98, 6400 train 77.20%, 1600 test 74.44%\n",
      "Time elapsed: 0:13:06.045018\n",
      "ep 45, loss: 20.56, 6400 train 77.34%, 1600 test 71.31%\n",
      "Time elapsed: 0:13:24.128261\n",
      "ep 46, loss: 20.36, 6400 train 77.88%, 1600 test 69.62%\n",
      "Time elapsed: 0:13:41.921867\n",
      "ep 47, loss: 20.46, 6400 train 77.14%, 1600 test 70.25%\n",
      "Time elapsed: 0:13:59.407476\n",
      "ep 48, loss: 19.59, 6400 train 78.44%, 1600 test 69.38%\n",
      "Time elapsed: 0:14:16.896400\n",
      "ep 49, loss: 18.99, 6400 train 78.81%, 1600 test 70.56%\n",
      "Time elapsed: 0:14:34.596426\n",
      "ep 50, loss: 19.09, 6400 train 79.17%, 1600 test 73.06%\n",
      "[[164.   0.   5.  12.   1.   4.   5.   6.]\n",
      " [  1. 114.   1.  11.  11.  33.  12.  28.]\n",
      " [  7.  10. 116.  15.  26.  19.   2.   3.]\n",
      " [ 15.   0.   1. 168.   0.   4.   0.   1.]\n",
      " [  6.  14.   3.  32. 145.   6.   4.   8.]\n",
      " [  1.   3.   0.  12.   0. 195.   1.   1.]\n",
      " [ 10.  11.   6.   8.   0.  26. 113.   6.]\n",
      " [ 23.   5.   6.   2.   0.   2.   2. 154.]]\n",
      "Time elapsed: 0:14:52.348933\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:14:52.422934\n",
      "total time in seconds: 892.422934293747\n",
      "ep 51, loss: 18.19, 6400 train 80.27%, 1600 test 70.12%\n",
      "Time elapsed: 0:15:10.325587\n",
      "ep 52, loss: 19.63, 6400 train 78.95%, 1600 test 73.38%\n",
      "Time elapsed: 0:15:27.964400\n",
      "ep 53, loss: 19.04, 6400 train 78.98%, 1600 test 73.88%\n",
      "Time elapsed: 0:15:45.662506\n",
      "ep 54, loss: 18.62, 6400 train 79.62%, 1600 test 71.00%\n",
      "Time elapsed: 0:16:03.298383\n",
      "ep 55, loss: 17.55, 6400 train 80.73%, 1600 test 68.19%\n",
      "Time elapsed: 0:16:20.981945\n",
      "ep 56, loss: 17.73, 6400 train 80.28%, 1600 test 74.94%\n",
      "Time elapsed: 0:16:38.495582\n",
      "ep 57, loss: 17.71, 6400 train 80.38%, 1600 test 73.19%\n",
      "Time elapsed: 0:16:55.847264\n",
      "ep 58, loss: 17.14, 6400 train 80.67%, 1600 test 69.12%\n",
      "Time elapsed: 0:17:13.129389\n",
      "ep 59, loss: 17.68, 6400 train 81.09%, 1600 test 74.06%\n",
      "Time elapsed: 0:17:30.475057\n",
      "ep 60, loss: 16.64, 6400 train 81.91%, 1600 test 71.94%\n",
      "[[164.   0.   3.  20.   1.   1.   0.   8.]\n",
      " [  1.  88.   5.  12.  13.  42.  15.  35.]\n",
      " [  5.   3. 133.  18.  14.  12.   2.  11.]\n",
      " [ 12.   0.   1. 172.   0.   4.   0.   0.]\n",
      " [  5.   8.   6.  41. 138.   6.   5.   9.]\n",
      " [  0.   0.   0.  11.   0. 198.   2.   2.]\n",
      " [ 12.   7.   8.  16.   0.  35.  97.   5.]\n",
      " [ 18.   2.   2.   6.   1.   2.   2. 161.]]\n",
      "Time elapsed: 0:17:47.793176\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:17:47.863221\n",
      "total time in seconds: 1067.8632214069366\n",
      "ep 61, loss: 17.04, 6400 train 81.16%, 1600 test 67.88%\n",
      "Time elapsed: 0:18:05.155136\n",
      "ep 62, loss: 16.63, 6400 train 81.36%, 1600 test 75.56%\n",
      "Time elapsed: 0:18:22.434269\n",
      "ep 63, loss: 16.13, 6400 train 82.06%, 1600 test 76.19%\n",
      "Time elapsed: 0:18:39.720607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 64, loss: 15.76, 6400 train 82.08%, 1600 test 74.06%\n",
      "Time elapsed: 0:18:57.225751\n",
      "ep 65, loss: 15.59, 6400 train 82.78%, 1600 test 78.19%\n",
      "Time elapsed: 0:19:14.846206\n",
      "ep 66, loss: 15.83, 6400 train 82.55%, 1600 test 76.06%\n",
      "Time elapsed: 0:19:32.654507\n",
      "ep 67, loss: 15.53, 6400 train 83.08%, 1600 test 78.44%\n",
      "Time elapsed: 0:19:50.356609\n",
      "ep 68, loss: 14.69, 6400 train 83.64%, 1600 test 79.06%\n",
      "Time elapsed: 0:20:08.195319\n",
      "ep 69, loss: 15.12, 6400 train 83.14%, 1600 test 74.06%\n",
      "Time elapsed: 0:20:25.916115\n",
      "ep 70, loss: 15.39, 6400 train 83.39%, 1600 test 74.44%\n",
      "[[132.   0.   3.  10.   1.   8.  11.  32.]\n",
      " [  0. 117.   7.   0.  10.  31.   5.  41.]\n",
      " [  4.   8. 141.   1.  15.  20.   2.   7.]\n",
      " [  6.   0.   5. 145.   2.  21.   2.   8.]\n",
      " [  2.  11.   7.   7. 169.  11.   3.   8.]\n",
      " [  0.   3.   0.   1.   0. 205.   1.   3.]\n",
      " [  3.  13.   7.   2.   0.  32. 104.  19.]\n",
      " [  4.   6.   3.   1.   0.   1.   1. 178.]]\n",
      "Time elapsed: 0:20:43.524310\n",
      "   Model saved to checkModel.pth\n",
      "total time needed to train network: 0:20:43.595392\n",
      "total time in seconds: 1243.5953924655914\n",
      "ep 71, loss: 15.07, 6400 train 83.38%, 1600 test 75.50%\n",
      "Time elapsed: 0:21:01.033381\n",
      "ep 72, loss: 14.42, 6400 train 84.47%, 1600 test 75.69%\n",
      "Time elapsed: 0:21:18.360501\n",
      "ep 73, loss: 14.43, 6400 train 84.52%, 1600 test 77.88%\n",
      "Time elapsed: 0:21:36.140209\n",
      "ep 74, loss: 13.95, 6400 train 84.77%, 1600 test 74.94%\n",
      "Time elapsed: 0:21:54.291630\n",
      "ep 75, loss: 13.90, 6400 train 84.55%, 1600 test 76.00%\n",
      "Time elapsed: 0:22:11.971303\n",
      "ep 76, loss: 13.82, 6400 train 84.72%, 1600 test 73.88%\n",
      "Time elapsed: 0:22:29.652501\n",
      "ep 77, loss: 13.87, 6400 train 84.78%, 1600 test 75.31%\n",
      "Time elapsed: 0:22:47.475359\n",
      "ep 78, loss: 13.74, 6400 train 85.25%, 1600 test 80.06%\n",
      "Time elapsed: 0:23:05.189451\n",
      "ep 79, loss: 13.21, 6400 train 85.69%, 1600 test 74.94%\n",
      "Time elapsed: 0:23:22.881116\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### Tracking training time ###\n",
    "##############################\n",
    "start_time = time.time() ## Added\n",
    "time_elapsed = 0  ## Added Line\n",
    "##############################\n",
    "\n",
    "###############################\n",
    "### Tracking nn performance ###\n",
    "###############################\n",
    "minibatch_loss_list, train_accuracy_list, test_accuracy_list = [], [], [] ## Added\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "# Main\n",
    "print(\"Using device: {}\"\n",
    "      \"\\n\".format(str(device)))\n",
    "########################################################################\n",
    "#######                      Loading Data                        #######\n",
    "########################################################################\n",
    "data = torchvision.datasets.ImageFolder(root=dataset)\n",
    "\n",
    "if train_val_split == 1:\n",
    "    # Train on the entire dataset\n",
    "    data = torchvision.datasets.ImageFolder(root=dataset,\n",
    "                        transform=transform('train'))\n",
    "    trainloader = torch.utils.data.DataLoader(data,\n",
    "                        batch_size=batch_size, shuffle=True);\n",
    "else:\n",
    "    # Split the dataset into trainset and testset\n",
    "    data = torchvision.datasets.ImageFolder(root=dataset)\n",
    "    data.len=len(data)\n",
    "    train_len = int((train_val_split)*data.len)\n",
    "    test_len = data.len - train_len\n",
    "    train_subset, test_subset = random_split(data, [train_len, test_len])\n",
    "    trainset = DatasetFromSubset(\n",
    "        train_subset, transform=transform('train'))\n",
    "    testset = DatasetFromSubset(\n",
    "        test_subset, transform=transform('test'))\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "    testloader = torch.utils.data.DataLoader(testset, \n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Get model, loss criterion and optimizer from student\n",
    "net = net.to(device)\n",
    "criterion = loss_func\n",
    "optimizer = optimizer\n",
    "# get weight initialization and lr scheduler, if appropriate\n",
    "weights_init = weights_init\n",
    "scheduler = scheduler\n",
    "\n",
    "# apply custom weight initialization, if it exists\n",
    "net.apply(weights_init)\n",
    "\n",
    "########################################################################\n",
    "#######                        Training                          #######\n",
    "########################################################################\n",
    "print(\"Start training...\")\n",
    "for epoch in range(1,epochs+1):\n",
    "    total_loss = 0\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in trainloader:           # Load batch\n",
    "        images, labels = batch \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = net(images)             # Process batch\n",
    "\n",
    "        loss = criterion(preds, labels) # Calculate loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()                 # Calculate gradients\n",
    "        optimizer.step()                # Update weights\n",
    "\n",
    "        output = preds.argmax(dim=1)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_images += labels.size(0)\n",
    "        total_correct += output.eq(labels).sum().item()\n",
    "        minibatch_loss_list.append(loss.item())  ## Added\n",
    "\n",
    "    # apply lr schedule, if it exists\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100 \n",
    "    train_accuracy_list.append(model_accuracy)  ## Added\n",
    "    print('ep {0}, loss: {1:.2f}, {2} train {3:.2f}%'.format(\n",
    "           epoch, total_loss, total_images, model_accuracy), end='')\n",
    "\n",
    "    if train_val_split < 1:\n",
    "        test_network(net,testloader, test_accuracy_list,\n",
    "                     print_confusion=(epoch % 10 == 0)) ## Added\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "   \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(net.state_dict(),'checkModel.pth')\n",
    "        print(\"   Model saved to checkModel.pth\")\n",
    "        time_elapsed = time.time() - start_time  ## Added Line\n",
    "        print(f'Time elapsed: {str(datetime.timedelta(seconds = time_elapsed))}') ## TIME\n",
    "    \n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(),'savedModel.pth')\n",
    "print(\"   Model saved to savedModel.pth\")\n",
    "time_elapsed = time.time() - start_time ## Added Line\n",
    "print(f'total time needed to train network: \\\n",
    "        {str(datetime.timedelta(seconds = time_elapsed))}\\ntotal time in seconds: {time_elapsed}') ## TIME\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#**        Data Information     **#\n",
    "###################################\n",
    "print(f'batch size: {batch_size}')\n",
    "print(f'learning rate: {learning_rate}')\n",
    "print(f'train_val_split: {train_val_split}')\n",
    "print(f'epochs: {epochs}')\n",
    "\n",
    "\n",
    "#############################\n",
    "#**         END           **#\n",
    "#############################\n",
    "\n",
    "\n",
    "# Getting count of each cat breed, should be close to 8*0.8*1000 initially..\n",
    "train_data_distribution = get_cat_count(trainloader, 'training data')\n",
    "# Getting count of each cat breed, should be close to 8*0.2*1000 initially..\n",
    "test_data_distribution = get_cat_count(testloader, 'test data')\n",
    "\n",
    "print(f'training data distribution - {train_data_distribution}')\n",
    "print(f'test data distribution - {test_data_distribution}')\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=epochs,\n",
    "                   iter_per_epoch=len(trainloader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy(train_acc_list=train_accuracy_list,\n",
    "              test_acc_list=test_accuracy_list,\n",
    "              results_dir=None)\n",
    "plt.show()\n",
    "\n",
    "net.cpu()\n",
    "show_examples(model=net, data_loader=testloader, class_dict=cat_dict)\n",
    "\n",
    "conf_matrix = compute_confusion_matrix(model=net, data_loader=testloader, device=torch.device('cpu'))\n",
    "print(conf_matrix)\n",
    "plot_confusion_matrix(conf_matrix, class_names=cat_dict.values(), test_data_distribution=test_data_distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
